# -*- coding: utf-8 -*-
"""Copy of BS_Net_3D_Planck.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j47W2CUEGdvaQ9_z-9cjUMMKFGkst3u7
"""

import torch
import functools
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# Define the neural network architecture
class ControlPointNet3D(nn.Module):
    def __init__(self, n_cp_x, n_cp_y, n_cp_z, n_cp_t, hidden_dim=128):
        super(ControlPointNet3D, self).__init__()
        self.fc1 = nn.Linear(4, hidden_dim)
        #self.fc2 = nn.Linear(hidden_dim,hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, hidden_dim)
        # Predict control points for the entire grid except for the initial time step
        self.fc4 = nn.Linear(hidden_dim, (n_cp_x) * (n_cp_y) * (n_cp_z) * (n_cp_t - 1) + (n_cp_t -1))
        self.n_cp_t = n_cp_t
        self.n_cp_x = n_cp_x
        self.n_cp_y = n_cp_y
        self.n_cp_z = n_cp_z

    def forward(self, params):
        x = torch.relu(self.fc1(params))
        #x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = self.fc4(x)
        #x = torch.sigmoid(x)
        C0, x = x[:,-n_cp_t+1:], x[:, :-n_cp_t+1]
        C0 = torch.sigmoid(C0)

        x = x.view(-1, self.n_cp_t-1, self.n_cp_x*self.n_cp_y*self.n_cp_z)
        x = torch.relu(x)

        x = x/torch.sum(x,dim = 2, keepdim = True)
        x = torch.einsum("ij,ijk->ijk", C0, x)
        return x.view(-1, self.n_cp_t-1, self.n_cp_x,self.n_cp_y,self.n_cp_z)

# B-spline basis function

def BsFun(i, d, t, Ln):
    if d == 0:
        return 1.0 if Ln[i - 1] <= t < Ln[i] else 0.0
    else:
        a = 0 if (Ln[d + i - 1] - Ln[i - 1]) == 0 else (t - Ln[i - 1]) / (Ln[d + i - 1] - Ln[i - 1])
        b = 0 if (Ln[d + i] - Ln[i]) == 0 else (Ln[d + i] - t) / (Ln[d + i] - Ln[i])
        return a * BsFun(i, d - 1, t, Ln) + b * BsFun(i + 1, d - 1, t, Ln)

# B-spline derivative basis function (first derivative)
def BsFun_derivative(i, d, t, Ln):
    if d == 0:
        return 0.0
    else:
        a = 0 if (Ln[d + i - 1] - Ln[i - 1]) == 0 else d / (Ln[d + i - 1] - Ln[i - 1])
        b = 0 if (Ln[d + i] - Ln[i]) == 0 else d / (Ln[d + i] - Ln[i])
        return a * BsFun(i, d - 1, t, Ln) - b * BsFun(i + 1, d - 1, t, Ln)

# Second derivative of B-spline
def BsFun_pp(i, d, t, Ln):
    if d < 2:
        return 0.0
    else:
        a = 0 if (Ln[d + i - 2] - Ln[i - 2]) == 0 else d * (d - 1) / ((Ln[d + i - 2] - Ln[i - 2]) ** 2)
        b = 0 if (Ln[d + i - 1] - Ln[i - 1]) == 0 else 2 * d * (d - 1) / ((Ln[d + i - 1] - Ln[i - 1]) ** 2)
        c = 0 if (Ln[d + i] - Ln[i]) == 0 else d * (d - 1) / ((Ln[d + i] - Ln[i]) ** 2)
        return a * BsFun(i, d - 2, t, Ln) - b * BsFun(i + 1, d - 2, t, Ln) + c * BsFun(i + 2, d - 2, t, Ln)

# B-spline knots and basis matrix
def BsKnots(n_cp, d, Ns):
    n_knots = n_cp + d + 1
    Ln = torch.zeros(n_knots)

    # Construct the knots vector
    for i in range(d + 1, n_knots - d - 1):
        Ln[i] = i - d
    Ln[n_knots - d - 1:] = n_cp - d  # The last d+1 elements should be the same

    # Parameter vector (linearly spaced)
    tk = torch.zeros(Ns)
    for i in range(1, Ns):
        tk[i] = tk[i - 1] + Ln[-1] / (Ns - 1)

    # B-spline basis matrix
    Bit = torch.zeros((Ns, n_cp))
    for j in range(n_cp):
        for i in range(Ns):
            Bit[i, j] = BsFun(j + 1, d, tk[i], Ln)

    Bit[Ns - 1, n_cp - 1] = 1
    return tk.contiguous(), Ln.contiguous(), Bit.contiguous()

# Precompute B-spline basis, first derivatives, and second derivatives
def precompute_bsplines(n_cp, d, Ns, Ln, tk):
    """
    Precompute the B-spline basis matrix, first derivatives, and second derivatives for efficiency.
    """
    Bit = torch.zeros((Ns, n_cp))
    Bit_derivative = torch.zeros((Ns, n_cp))
    Bit_pp = torch.zeros((Ns, n_cp))

    for j in range(n_cp):
        for i in range(Ns):
            Bit[i, j] = BsFun(j + 1, d, tk[i], Ln)
            Bit_derivative[i, j] = BsFun_derivative(j + 1, d, tk[i], Ln)
            Bit_pp[i, j] = BsFun_pp(j + 1, d, tk[i], Ln)

    return Bit.contiguous(), Bit_derivative.contiguous(), Bit_pp.contiguous()


def compute_bspline_surface_precomputed_new(U_full, Bit_t, Bit_x, Bit_y, Bit_z,

                                            Bit_t_derivative, Bit_x_derivative, Bit_y_derivative, Bit_z_derivative, Bit_x_pp,

                                            Bit_y_pp, Bit_z_pp):

    #Jasmine's faster version of the code below.
    if U_full.ndim <5:
      U_full = U_full.reshape(1,*U_full.shape)
    n_data, n_cp_t, n_cp_x, n_cp_y, n_cp_z = U_full.shape
    Nt, Nx, Ny, Nz = Bit_t.shape[0], Bit_x.shape[0], Bit_y.shape[0], Bit_z.shape[0]

    # Compute the surface and its derivatives

    B_surface = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x, Bit_y, Bit_z)
    B_surface_t = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t_derivative, Bit_x, Bit_y, Bit_z)
    B_surface_x = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x_derivative, Bit_y, Bit_z)
    B_surface_y = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x, Bit_y_derivative, Bit_z)
    B_surface_z = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x, Bit_y, Bit_z_derivative)
    B_surface_xx = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x_pp, Bit_y, Bit_z)
    B_surface_yy = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x, Bit_y_pp, Bit_z)
    B_surface_zz = torch.einsum('qijkl,ti,xj,yk,zl->qtxyz', U_full, Bit_t, Bit_x, Bit_y, Bit_z_pp)

    # Laplacian (sum of second derivatives in each spatial direction)
    B_surface_laplacian = B_surface_xx + B_surface_yy + B_surface_zz


    return B_surface, B_surface_t, B_surface_x, B_surface_y, B_surface_z, B_surface_laplacian


# Gaussian PDF function for the initial condition
def gaussian_pdf(grid_x, grid_y, grid_z, Bit_t, Bit_x, Bit_y, Bit_z, center, width):
    cx, cy, cz = center
    ctrl_dist = torch.exp(-((grid_x - cx) ** 2 + (grid_y - cy) ** 2 + (grid_z - cz) ** 2) / (2 * width ** 2))
    print(torch.sum(ctrl_dist))
    proj_U_Full = torch.einsum('ijkl,ti,xj,yk,zl->txyz', ctrl_dist.reshape(1, *ctrl_dist.shape), Bit_t, Bit_x, Bit_y, Bit_z)[0,:,:,:]
    f = 1/torch.sum(proj_U_Full)
    print(f)
    return f*ctrl_dist

# Initialize parameters
T = 1e-2  # Maximum time bound
#L = 1.0   # Space bound in each dimension
n_cp_t = 21  # Number of control points in time
n_cp_x = 21  # Number of control points in x
n_cp_y = 21  # Number of control points in y
n_cp_z = 21  # Number of control points in z
d = 3       # Order of B-spline (3rd order polynomial)
hidden_dim = 64  # Hidden dimension size
nm = 1e-9
Ns = 101 # number of samples
D = 0.0003#0.0003 worked  # Diffusion coefficient

max_x = 150*nm
min_x =-150*nm

# Generate t, x, y, z with control points grid size
x_vals = torch.linspace(min_x, max_x, n_cp_x)
y_vals = torch.linspace(min_x, max_x, n_cp_y)
z_vals = torch.linspace(min_x, max_x, n_cp_z)
t_vals = torch.linspace(0, T, n_cp_t)
# Create meshgrid for the 3D control points grid
X, Y, Z = torch.meshgrid(x_vals, y_vals, z_vals, indexing='ij')



# Generate t, x, y, z with control points grid size
x_samp = torch.linspace(min_x, max_x, Ns)
y_samp = torch.linspace(min_x, max_x, Ns)
z_samp = torch.linspace(min_x, max_x, Ns)
t_samp = torch.linspace(0, T, Ns)

Xs, Ys, Zs = torch.meshgrid(x_samp, y_samp, z_samp, indexing='ij')


# Generate B-spline knots and precompute basis functions, derivatives, and second derivatives
tk_t, Ln_t, Bit_t = BsKnots(n_cp_t, d, Ns)
tk_x, Ln_x, Bit_x = BsKnots(n_cp_x, d, Ns)
tk_y, Ln_y, Bit_y = BsKnots(n_cp_y, d, Ns)
tk_z, Ln_z, Bit_z = BsKnots(n_cp_z, d, Ns)

# Precompute B-splines, derivatives, and second derivatives
Bit_t, Bit_t_derivative, _  = precompute_bsplines(n_cp_t, d, Ns, Ln_t, tk_t)
Bit_x, Bit_x_derivative, Bit_x_pp = precompute_bsplines(n_cp_x, d, Ns, Ln_x, tk_x)
Bit_y, Bit_y_derivative, Bit_y_pp = precompute_bsplines(n_cp_y, d, Ns, Ln_y, tk_y)
Bit_z, Bit_z_derivative, Bit_z_pp = precompute_bsplines(n_cp_z, d, Ns, Ln_z, tk_z)

# Define the initial condition with the size of control points grid
center = (0,0,0)#(-150 * nm, -150 * nm, -150 * nm)
width = torch.tensor(35 * nm)
initial_condition0 = gaussian_pdf(X, Y, Z, Bit_t, Bit_x, Bit_y, Bit_z, center=center, width=width)
center = (0,90*nm,0)#(-150 * nm, -150 * nm, -150 * nm)
width = torch.tensor(15 * nm)
initial_condition1 = gaussian_pdf(X, Y, Z, Bit_t, Bit_x, Bit_y, Bit_z, center=center, width=width)
center = (90*nm,0,90*nm)#(-150 * nm, -150 * nm, -150 * nm)
width = torch.tensor(45 * nm)
initial_condition2 = gaussian_pdf(X, Y, Z, Bit_t, Bit_x, Bit_y, Bit_z, center=center, width=width)
center = (0,0,0)#(-150 * nm, -150 * nm, -150 * nm)
width = torch.tensor(12 * nm)
initial_condition3 = gaussian_pdf(X, Y, Z, Bit_t, Bit_x, Bit_y, Bit_z, center=center, width=width)

initial_condition = torch.stack([initial_condition0,
             initial_condition1,
             initial_condition2, 
             initial_condition3], dim=0)
params = torch.tensor([[0 , 0  , 0 , 35],
                       [0 , 130, 0 , 15],
                       [90, 0  , 90, 45],
                       [0 , 0  , 0 , 12]
                       ], dtype = torch.float32)

print(
torch.sum(initial_condition0),
torch.sum(initial_condition1),
torch.sum(initial_condition2))

# Create neural network

model = ControlPointNet3D(n_cp_x, n_cp_y, n_cp_z, n_cp_t, hidden_dim)
optimizer_a = optim.Adam(model.parameters(), lr=0.0001)
optimizer_l = optim.LBFGS(model.parameters(), history_size=100)
# define closure for LBFGS

def closure():
    optimizer_l.zero_grad()
        # Predict control points
    U_pred = model(params)
    #print(U_pred.shape)

    # Construct the full control points tensor with boundary conditions
    U_full = torch.zeros((batch_size,n_cp_t, n_cp_x, n_cp_y, n_cp_z))
    U_full[:,0, :, :, :] = initial_condition  # Set initial condition at t=0
    U_full[:,1:,:,:, :] = U_pred  # Predicted control points


    # Compute B-spline surface, time derivative, and Laplacian using precomputed values
    B_surface, B_surface_t, B_surface_x, B_surface_y, B_surface_z, B_surface_laplacian = compute_bspline_surface_precomputed_new(
        U_full, Bit_t, Bit_x, Bit_y, Bit_z, Bit_t_derivative,
        Bit_x_derivative, Bit_y_derivative, Bit_z_derivative, Bit_x_pp, Bit_y_pp, Bit_z_pp)

    # Compute the Fokker-Planck PDE residual: B_surface_t = D * Laplacian
    #residual = B_surface_t - D* B_surface_laplacian
    residual = B_surface_t - dF*(B_surface) -F*(B_surface_x+B_surface_y+B_surface_z)- D* B_surface_laplacian

    # Compute physics-informed loss (MSE of the residual)
    physics_loss = 10*torch.sum(residual ** 2)

    # Backpropagation
    physics_loss.backward()
    return physics_loss
# Training loop
epochs = 801
batch_size = params.shape[0]
#params = torch.tensor([], dtype=torch.float32)  # Placeholder input parameter
alpha =torch.tensor([ -35*nm, 0, 35*nm])
r = torch.stack([Xs,Ys,Zs], dim=-1)-alpha
F= 0#12*torch.pow((torch.einsum("abcd,abcd->abc",r,r)),0.5)
dF = 0#12

for epoch in tqdm(range(epochs), desc="Training Epochs"):
    #break

    optimizer_a.zero_grad()


    # Predict control points
    U_pred = model(params)

    # Construct the full control points tensor with boundary conditions
    U_full = torch.zeros((batch_size,n_cp_t, n_cp_x, n_cp_y, n_cp_z))
    U_full[:, 0, :, :, :] = initial_condition  # Set initial condition at t=0
    U_full[:,1:, :, :, :] = U_pred # Predicted control points
    # Compute B-spline surface, time derivative, and Laplacian using precomputed values

    B_surface, B_surface_t, B_surface_x, B_surface_y, B_surface_z, B_surface_laplacian = compute_bspline_surface_precomputed_new(
        U_full, Bit_t, Bit_x, Bit_y, Bit_z, Bit_t_derivative,
        Bit_x_derivative, Bit_y_derivative, Bit_z_derivative, Bit_x_pp, Bit_y_pp, Bit_z_pp)

    # Compute the Fokker-Planck PDE residual: B_surface_t = D * Laplacian
    residual = B_surface_t - dF*(B_surface) -F*(B_surface_x+B_surface_y+B_surface_z)- D* B_surface_laplacian
    
    
    #print(residual.shape)
    # Compute physics-informed loss (MSE of the residual)
    physics_loss = 10*torch.sum(residual ** 2)

    #Step with Adam optimizer
    #optimizer.step()

    if epoch<600 or epoch%20<10:
        physics_loss.backward()
        optimizer_a.step()
    else:

        optimizer_l.step(closure)

    if epoch %10 == 0:
      print(f'Epoch {epoch}, Loss: {physics_loss.item():2.12f}')

plt.imshow(B_surface.detach().numpy()[0,13,:,:,7])
plt.colorbar(label='Probability Density')
torch.sum(B_surface[0,:,:,:,:])

#plt.imshow(B_surface_np[:,50,:,50])
plt.plot(B_surface.detach().numpy()[0,:,Ns//2,:,Ns//2])

# Visualization (e.g., plotting slices at specific times)
with torch.no_grad():
    # Use the trained model to predict control points
    U_pred = model(params)

    # Construct the full control points tensor
    U_full = torch.zeros((batch_size, n_cp_t, n_cp_x, n_cp_y, n_cp_z))
    U_full[:,0, :, :, :] = initial_condition  # Initial condition
    U_full[:,1:, :, :, :] = U_pred

    # Compute the B-spline surface
    B_surface = compute_bspline_surface_precomputed_new(U_full, Bit_t, Bit_x, Bit_y, Bit_z,
                                                        Bit_t_derivative, Bit_x_derivative, Bit_y_derivative, Bit_z_derivative, Bit_x_pp,
                                                        Bit_y_pp, Bit_z_pp)[0]

    # Convert to numpy for plotting
    B_surface_np = B_surface.numpy()

    # Plotting a slice at t = mid_time
    mid_time = 3#int(n_cp_t // 2)
    plt.figure(figsize=(8, 6))
    plt.imshow(B_surface_np[0,mid_time, :,  :, int(n_cp_z / 2)], extent=[x_vals.min(), x_vals.max(), y_vals.min(), y_vals.max()], origin='lower')
    plt.colorbar(label='Probability Density')
    plt.title(f'Probability Density at t={t_vals[mid_time]:.2f}, z=0')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.show()

a = torch.randn(13, 5,3,7,2)
b = (a/torch.sum(a, dim=(2,3,4), keepdim=True))

import utils

utils.plot_all_frames(B_surface.detach().numpy()[0])

